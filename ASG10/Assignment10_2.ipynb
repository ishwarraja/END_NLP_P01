{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment10_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uRsrPeP0LwI",
        "outputId": "ee8c7378-4e67-4d1d-991c-90f24898c039"
      },
      "source": [
        "!python -m spacy download de\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=81c9bffedceb4ad3b189ae3c932859eaf783a952ae24b716d750ea54c669ac6d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8r74dfmt/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg8f-0F0-oLr"
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ba-JQ-5-oO8"
      },
      "source": [
        "\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaRSSvPd-oSb"
      },
      "source": [
        "spacy_en = spacy.load('en')\n",
        "spacy_de = spacy.load('de')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RteMyE6q-oVp"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_de(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFfZuFBw_DzX"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            include_lengths = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RYcpm1s_D20",
        "outputId": "e0cd4b6c-fd49-429a-cdfd-5f77636c002c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.de'), fields=(SRC, TRG))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 492kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 169kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 161kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1CZcJP_D5z"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62oIAGxy_D8p"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device,\n",
        "    sort = True,\n",
        "    sort_key = lambda x: len(x.src)\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrbIUh4v_D_n",
        "outputId": "61db88d0-4a13-4401-9559-36ee60d30811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgumo79S_ECn"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = torch.nn.Embedding(input_dim, emb_dim)\n",
        "    self.rnn = torch.nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "    self.fc = torch.nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "    self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src, src_len):\n",
        "    # src -> [src len, batch size]\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    # embedded -> [src len, batch size, emb_dim]\n",
        "\n",
        "    packed_embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, src_len.cpu())\n",
        "    packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "    outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "    # outputs -> [src len, batch size, enc_hid_dim * num_directions]\n",
        "    #         -> [src len, batch size, enc_hid_dim * 2]\n",
        "    # hidden -> [num_layers * num_directions, batch size, enc_hid_dim]\n",
        "    #        -> [2, batch size, enc_hid_dim]\n",
        "\n",
        "    concatenated = torch.cat((hidden[-2, :, :], hidden[-1, :, :]),dim=1)\n",
        "    # concatenated -> [batch size, enc_hid_dim * 2]\n",
        "\n",
        "    hidden = torch.tanh(self.fc(concatenated))\n",
        "    # hidden -> [batch size, dec_hid_him]\n",
        "\n",
        "    return outputs, hidden\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN14XZP0_EFr"
      },
      "source": [
        "class Attention(torch.nn.Module):\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "    super().__init__()\n",
        "    self.attn = torch.nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "    self.v = torch.nn.Linear(dec_hid_dim, 1, bias=False)\n",
        "\n",
        "  def forward(self, encoder_outputs, hidden, mask):\n",
        "    # encoder_outputs -> [src len, batch size, enc_hid_dim * 2]\n",
        "    # hidden -> [batch size, dec_hid_dim]\n",
        "\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "    batch_size = encoder_outputs.shape[1]\n",
        "\n",
        "    # Repeat hidden state for each time step in src len\n",
        "    hidden = hidden.unsqueeze(0).repeat(src_len, 1, 1)\n",
        "    # hidden -> [src len, batch size, dec_hid_dim]\n",
        "\n",
        "    concatenated = torch.cat((encoder_outputs, hidden), dim=2)\n",
        "    # concatenated -> [src len, batch size, (enc_hid_dim * 2) + dec_hid_dim]\n",
        "\n",
        "    energy = torch.tanh(self.attn(concatenated))\n",
        "    # energy -> [src len, batch size, dec_hid_dim]\n",
        "\n",
        "    attention = self.v(energy).squeeze(2)\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\n",
        "    # attention -> [src len, batch size]\n",
        "\n",
        "    return F.softmax(attention, dim=0)\n",
        "    # return dim -> [src len, batch size]\n",
        "    # the `src len` values of each item in batch add up to 1 (because of softmax)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8rioJdP_EIO"
      },
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "    super().__init__()\n",
        "\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.embedding = torch.nn.Embedding(output_dim, emb_dim)\n",
        "    self.rnn = torch.nn.GRU(emb_dim + (2 * enc_hid_dim), dec_hid_dim)\n",
        "    self.fc = torch.nn.Linear(emb_dim + dec_hid_dim + (2 * enc_hid_dim), output_dim)\n",
        "    self.dropout = torch.nn.Dropout(dropout)\n",
        "    self.attn = attention\n",
        "\n",
        "  def forward(self, input, encoder_outputs, hidden, mask):\n",
        "    \n",
        "    # input -> [batch size]\n",
        "    # encoder_outputs -> [src len, batch size, enc_hid_dim * 2]\n",
        "    # hidden -> [batch size, dec_hid_dim]\n",
        "\n",
        "    input = input.unsqueeze(0)\n",
        "    # input -> [1, batch size]\n",
        "\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    # embedded -> [1, batch size, emb_dim]\n",
        "\n",
        "    a = self.attn(encoder_outputs, hidden, mask)\n",
        "    # a -> [src len, batch size]\n",
        "\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    # encoder_outputs -> [batch size, src len, enc_hid_dim * 2]\n",
        "\n",
        "    a = a.permute(1, 0).unsqueeze(1)\n",
        "    # a -> [batch size, 1, src len]\n",
        "\n",
        "    weighted = torch.bmm(a, encoder_outputs).permute(1, 0, 2)\n",
        "    # weighted -> [1, batch size, enc_hid_dim * 2]\n",
        "\n",
        "    outputs, hidden = self.rnn(torch.cat((embedded, weighted), dim=2), hidden.unsqueeze(0))\n",
        "    # outputs -> [1, batch size, dec_hid_dim]\n",
        "    # hidden -> [1, batch size, dec_hid_dim]\n",
        "\n",
        "    fc_input = torch.cat((embedded, outputs, weighted), dim=2)\n",
        "    # fc_input -> [1, batch size, emb_dim + dec_hid_dim + (2 * enc_hid_dim)]\n",
        "\n",
        "    predictions = self.fc(fc_input).squeeze(0)\n",
        "    # predictions -> [batch size, output_dim]\n",
        "\n",
        "    return predictions, hidden.squeeze(0), a.squeeze(1)\n",
        "    # return dimensions\n",
        "    # predictions -> [batch size, output_dim]\n",
        "    # hidden -> [batch size, dec_hid_dim]\n",
        "    # a -> [batch size, src len]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz2AjVaL_ELa"
      },
      "source": [
        "class Seq2Seq(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "\n",
        "  def create_mask(self, src):\n",
        "    mask = (src != self.src_pad_idx)\n",
        "    # mask -> [src len, batch size]\n",
        "    return mask\n",
        "\n",
        "  def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
        "\n",
        "    # src -> [src len, batch size]\n",
        "    # trg -> [trg len, batch size]\n",
        "\n",
        "    batch_size = trg.shape[1]\n",
        "    trg_len = trg.shape[0]\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "    # decoder outputs\n",
        "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "    # pass src through encoder\n",
        "    encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "    # encoder_outputs -> [src len, batch size, enc_hid_dim * 2]\n",
        "    # hidden -> [batch size, dec_hid_him]\n",
        "\n",
        "    input = trg[0, :]\n",
        "    # input -> [batch size]\n",
        "\n",
        "    mask = self.create_mask(src)\n",
        "\n",
        "    for t in range(1, trg_len):\n",
        "\n",
        "      output, hidden, attn = self.decoder(input, encoder_outputs, hidden, mask)\n",
        "      # output -> [batch size, output_dim]\n",
        "      # hidden -> [batch size, dec_hid_dim]\n",
        "      # attn -> [batch size, src len]\n",
        "\n",
        "      outputs[t] = output\n",
        "\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "      top1 = output.argmax(1)\n",
        "      # top1 -> [batch size]\n",
        "\n",
        "      input = trg[t] if teacher_force else top1\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9WHNiSt_EOS"
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      torch.nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "    else:\n",
        "      torch.nn.init.constant_(param.data, 0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LAdtA01_ERQ"
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYbVzQmt_EVC",
        "outputId": "756918e4-25ae-4745-b9fd-4b814083fcbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "ENC_HID_DIM = 128\n",
        "DEC_HID_HIM = 128\n",
        "\n",
        "DROPOUT = 0.3\n",
        "\n",
        "src_pad_idx = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_HIM, DROPOUT)\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_HIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_HIM, DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, src_pad_idx, device).to(device)\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5893, 128)\n",
              "    (rnn): GRU(128, 128, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(7873, 128)\n",
              "    (rnn): GRU(384, 128)\n",
              "    (fc): Linear(in_features=512, out_features=7873, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (attn): Attention(\n",
              "      (attn): Linear(in_features=384, out_features=128, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GgYL07i_EZM"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZAMRUf8_EuH"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH1DTN6s_Exb"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih7Y1LcrAWQv"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qD1KDR8BCgr"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUvmt4KIAazk",
        "outputId": "e9b4b9bb-c41d-4925-ac70-a10f2f99c2d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 24s\n",
            "\tTrain Loss: 4.566 | Train PPL:  96.139\n",
            "\t Val. Loss: 5.706 |  Val. PPL: 300.717\n",
            "Epoch: 02 | Time: 0m 24s\n",
            "\tTrain Loss: 4.309 | Train PPL:  74.386\n",
            "\t Val. Loss: 5.438 |  Val. PPL: 229.969\n",
            "Epoch: 03 | Time: 0m 24s\n",
            "\tTrain Loss: 4.059 | Train PPL:  57.913\n",
            "\t Val. Loss: 5.256 |  Val. PPL: 191.641\n",
            "Epoch: 04 | Time: 0m 24s\n",
            "\tTrain Loss: 3.744 | Train PPL:  42.261\n",
            "\t Val. Loss: 4.904 |  Val. PPL: 134.859\n",
            "Epoch: 05 | Time: 0m 24s\n",
            "\tTrain Loss: 3.441 | Train PPL:  31.220\n",
            "\t Val. Loss: 4.543 |  Val. PPL:  94.010\n",
            "Epoch: 06 | Time: 0m 24s\n",
            "\tTrain Loss: 3.156 | Train PPL:  23.478\n",
            "\t Val. Loss: 4.254 |  Val. PPL:  70.400\n",
            "Epoch: 07 | Time: 0m 24s\n",
            "\tTrain Loss: 2.908 | Train PPL:  18.324\n",
            "\t Val. Loss: 4.043 |  Val. PPL:  56.980\n",
            "Epoch: 08 | Time: 0m 24s\n",
            "\tTrain Loss: 2.694 | Train PPL:  14.784\n",
            "\t Val. Loss: 3.890 |  Val. PPL:  48.911\n",
            "Epoch: 09 | Time: 0m 24s\n",
            "\tTrain Loss: 2.522 | Train PPL:  12.448\n",
            "\t Val. Loss: 3.674 |  Val. PPL:  39.391\n",
            "Epoch: 10 | Time: 0m 24s\n",
            "\tTrain Loss: 2.355 | Train PPL:  10.540\n",
            "\t Val. Loss: 3.755 |  Val. PPL:  42.739\n",
            "Epoch: 11 | Time: 0m 24s\n",
            "\tTrain Loss: 2.240 | Train PPL:   9.396\n",
            "\t Val. Loss: 3.481 |  Val. PPL:  32.488\n",
            "Epoch: 12 | Time: 0m 24s\n",
            "\tTrain Loss: 2.103 | Train PPL:   8.193\n",
            "\t Val. Loss: 3.436 |  Val. PPL:  31.077\n",
            "Epoch: 13 | Time: 0m 24s\n",
            "\tTrain Loss: 1.997 | Train PPL:   7.368\n",
            "\t Val. Loss: 3.346 |  Val. PPL:  28.391\n",
            "Epoch: 14 | Time: 0m 24s\n",
            "\tTrain Loss: 1.913 | Train PPL:   6.776\n",
            "\t Val. Loss: 3.374 |  Val. PPL:  29.185\n",
            "Epoch: 15 | Time: 0m 24s\n",
            "\tTrain Loss: 1.838 | Train PPL:   6.284\n",
            "\t Val. Loss: 3.346 |  Val. PPL:  28.383\n",
            "Epoch: 16 | Time: 0m 24s\n",
            "\tTrain Loss: 1.771 | Train PPL:   5.875\n",
            "\t Val. Loss: 3.438 |  Val. PPL:  31.135\n",
            "Epoch: 17 | Time: 0m 23s\n",
            "\tTrain Loss: 1.715 | Train PPL:   5.558\n",
            "\t Val. Loss: 3.381 |  Val. PPL:  29.405\n",
            "Epoch: 18 | Time: 0m 23s\n",
            "\tTrain Loss: 1.662 | Train PPL:   5.268\n",
            "\t Val. Loss: 3.340 |  Val. PPL:  28.208\n",
            "Epoch: 19 | Time: 0m 23s\n",
            "\tTrain Loss: 1.606 | Train PPL:   4.981\n",
            "\t Val. Loss: 3.207 |  Val. PPL:  24.715\n",
            "Epoch: 20 | Time: 0m 23s\n",
            "\tTrain Loss: 1.559 | Train PPL:   4.755\n",
            "\t Val. Loss: 3.263 |  Val. PPL:  26.139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noGPl5v7AnEx",
        "outputId": "63de993d-e0bc-4774-b4fe-3aea036e4bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} |  Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.185 |  Test PPL:  24.158 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB_CUb5lAsnP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(111)\n",
        "\n",
        "  attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "  cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "  ax.tick_params(labelsize=15)\n",
        "  ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], rotation=45)\n",
        "  ax.set_yticklabels(['']+translation)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "  plt.close()\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4nZP0nfEKD0"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  if isinstance(sentence, str):\n",
        "    spacy_en = spacy.load('en')\n",
        "    tokens = [token.text.lower() for token in spacy_en(sentence)]\n",
        "  else:\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "  tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "  src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "  src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "  src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "  mask = model.create_mask(src_tensor)\n",
        "\n",
        "  trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "  attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "\n",
        "  for i in range(max_len):\n",
        "\n",
        "    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output, hidden, attention = model.decoder(trg_tensor, encoder_outputs, hidden, mask)\n",
        "\n",
        "      attentions[i] = attention\n",
        "\n",
        "      pred_token = output.argmax(1).item()\n",
        "\n",
        "      trg_indexes.append(pred_token)\n",
        "\n",
        "      if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "        break\n",
        "\n",
        "  trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "  return trg_tokens[1:], attentions[:len(trg_tokens)-1]\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m0ZUyF9C8Kk"
      },
      "source": [
        "\n",
        "\n",
        "def translate_and_display_attention(idx):\n",
        "\n",
        "  src = vars(train_data.examples[idx])['src']\n",
        "  trg = vars(train_data.examples[idx])['trg']\n",
        "\n",
        "  print(f'src: ${src}')\n",
        "  print(f'trg: ${trg}')\n",
        "\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  print(f'predicted: {translation}')\n",
        "\n",
        "  display_attention(src, translation, attention)\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv2NJtoJDGv4",
        "outputId": "fafbd1b5-a057-483b-8ac3-1f1ecbec22b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "translate_and_display_attention(1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src: $['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']\n",
            "trg: $['mehrere', 'männer', 'mit', 'schutzhelmen', 'bedienen', 'ein', 'antriebsradsystem', '.']\n",
            "predicted: ['mehrere', 'männer', 'mit', 'schutzhelmen', 'bedienen', 'ein', '<unk>', '<unk>', '.', '<eos>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfMTyRv7DK9j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}